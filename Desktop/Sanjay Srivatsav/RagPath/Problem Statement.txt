In the current landscape of artificial intelligence, many applications powered by Large Language
Models (LLMs) are constrained by a fundamental limitation: their knowledge is static.
Retrieval-Augmented Generation (RAG) systems, while powerful, often rely on a knowledge base that
is a mere snapshot in time. This creates a "knowledge cutoff," where an AI assistant can become
instantly obsolete. Imagine a financial chatbot unaware of a market-moving announcement made
minutes ago, or a customer service bot providing information based on documentation that was
updated yesterday. In a world that operates in real-time, these delays are critical failures

The core technology for this challenge is Pathway, a data processing framework designed specifically
for building AI pipelines over live data streams. It allows developers to define complex AI workflows
that can process information incrementally, enabling extremely low-latency updates. Its unique
architecture unifies batch and streaming data, meaning the same code can be prototyped on static
files and then deployed to a live data stream, drastically reducing development complexity. This
challenge provides an opportunity to harness this powerful engine to build the next generation of
intelligent, real-time thinking applications.


Your challenge is to design, build, and deploy a Retrieval-Augmented Generation (RAG) application
using the Pathway framework that connects to a dynamic, continuously updating data source. The
application's core function must be to provide answers that reflect the absolute latest state of the
source data, updating its knowledge base and potential responses in real-time as new information
arrives, is modified, or is deleted, without requiring manual restarts or batch re-indexing.

A core requirement of this challenge is that all projects must connect to a data source that is
genuinely dynamic‚Äîone that changes over the course of the hackathon. While using a static dataset
is acceptable for initial development, the final submitted project must demonstrate its ability to
handle a live, evolving data stream.

OUR PROBLEM STATEMENT :

üß© Problem Statement

Modern engineering teams rely on continuously evolving documentation‚ÄîAPI references, design specs, runbooks, and incident notes‚Äîoften stored in shared folders, internal portals, or collaborative repositories. However, most AI documentation assistants index this information periodically or statically, causing them to provide outdated or incorrect answers shortly after documents are updated.

This leads to:

Engineers following obsolete instructions

Increased onboarding friction

Production mistakes due to stale runbooks

Loss of trust in AI assistants

There is a need for a documentation assistant that stays accurate in real time as documents change.

üí° Proposed Solution

Build a real-time Retrieval-Augmented Generation (RAG) assistant using the Pathway framework that continuously ingests documentation updates from a live data source (e.g., shared folder, API, or simulated document stream). As documents are added, edited, or removed, the system incrementally updates its knowledge base, ensuring that answers always reflect the latest version of the documentation, without restarts or re-indexing.

Core Requirement Clarified (in judge terms)

‚ÄúExternally changing data‚Äù means:

Changes happen outside your code

Data updates during runtime

Your system reacts automatically

üëâ Editing a Python list or re-running a script ‚ùå
üëâ External source updates triggering Pathway streams ‚úÖ


BEST OPTION (Strongly Recommended)
‚úÖ External Data Source: Shared Documentation via HTTP / Git-backed API
(Simulated Google Drive / Confluence / Internal Wiki)
üîπ What We Do

We simulate a real enterprise documentation system using:

A publicly hosted JSON / Markdown endpoint

Content changes pushed externally (Git commit, file update, API change)

Pathway ingests updates continuously

This is 100% acceptable and common in hackathons.





